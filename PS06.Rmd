---
title: 'STAT/MATH 495: Problem Set 06'
author: "Sara Culhane"
date: '2017-10-17'
output:
  html_document:
    collapsed: no
    df_print: kable
    smooth_scroll: no
    toc: yes
    toc_depth: 2
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '2'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, fig.width=8, fig.height=4.5, message=FALSE, warning = FALSE
  )
set.seed(76)

# Load packages
library(tidyverse)
library(broom)
library(knitr)
```





# Collaboration

Please indicate who you collaborated with on this assignment: 





# Setup

Define truth, which again we know for the purposes of this assignment, but in
practice we won't:

* the true function f(x) i.e. the signal
* the true epsilon i.e. the noise, which in this case is Normal$(0, sd=\sigma)$.
Hence the standard deviation $\sigma$ determines the amount of noise.

```{r}
f <- function(x) {
  x^2
}
sigma <- 0.3
```

This is the target point we'll be trying to predict: $(0.95, f(0.95)) = (0.95, 0.95^2) = (0.95, 0.9025)$, Thus, the test set is just `x=0.95`

```{r}
x0 <- 0.95
test_set <- data_frame(x=x0)
```

This function generates a random sample of size $n$; think of this as a "get new
data" function. Random in terms of both:

* (New) the predictor x (uniform on [0,1])
* the amount of noise $\epsilon$

```{r}
generate_sample <- function(f, n, sigma) {
  sample <- data_frame(
    x = runif(n = n, min = 0, max = 1),
    f_x = f(x),
    epsilon = rnorm(n = n, mean = 0, sd = sigma),
    y = f_x + epsilon
  )
  # Recall: We don't observe f(x) and epsilon, just (x, y)
  sample <- sample %>% 
    select(x, y)
  
  return(sample)
}
```

Define

* The number $n$ of observations $(x_i, y_i)$ in each sample. In the handout,
$n=100$ to keep plots uncrowded. Here we boost to $n=500$
* Number of samples of size $n$ to consider

```{r}
n <- 500
n_sample <- 10000
```


# Computation

```{r}
set.seed(10)
data <- data.frame(generate_sample(f,n,sigma))
z <- list()
full <- function(f,n,sigma) {
  for (i in 1:n_sample) {
    z[[i]] <- generate_sample(f,n,sigma)
    
  }
  return(z)
}
samp <-full(f,n,sigma)
preds <- rep(NA,n_sample)
m <-  rep(NA,n_sample)
mod1 <- function(list) {
  for (i in 1:length(list)) {
    m <- lm(y ~ x, data=data.frame(list[[i]]))
    preds[i] <- predict(m, test_set)

  }
  return(preds)
}
results <- mod1(samp)
```

```{r}
t <- rep(NA,n_sample)
mod2 <- function(list) {
  for (i in 1:length(list)) {
    preds[i] <- as.numeric(predict(smooth.spline(list[[i]]$x,list[[i]]$y,df=99),test_set)$y)


  }
  return(preds)
}
results2 <- mod2(samp)
ymean <- rep(NA,n_sample)

ys <- list()
ydata <- function(n_sample){
  for (i in 1:n_sample){
    ys[[i]] <- f(0.95)+rnorm(n,0,1)
  }
  return(ys)
}
values <- ydata(n_sample)

y_m <- function(y) {
  for (i in 1:length(y)) {
    ymean[i] <- mean(data.frame(y[[i]])$y)
  }
  return(ymean)
}
ymeans <- y_m(values)
```  

# Tables

As done in Lec 2.7, for both

* An `lm` regression AKA a `smooth.splines(x, y, df=2)` model fit 
* A `smooth.splines(x, y, df=99)` model fit 

output tables comparing:

|  MSE| bias_squared|   var| irreducible|   sum|
|----:|------------:|-----:|-----------:|-----:|
|     X|           X  |     X |      X |         X |

where `sum = bias_squared + var + irreducible`. You can created cleanly formatted tables like the one above by piping a data frame into `knitr::kable(digits=4)`.

```{r, include = FALSE}
MSE <- function(x) { # simple function for RMSE
  r <- mean(x^2)
  return(r)
}


bias <-function(yhat) { 
  bias <- mean(ymeans-yhat) 
  return(bias)}

bias2L <- bias(results)^2
bias2S <- bias(results2)^2

```

```{r}
lm_MSE <- MSE(ymeans-results)
lm_bias2 <- bias2L
lm_var <- var(ymeans-results)
lm_ir <- var(ymeans)
l_sum <- lm_bias2+lm_var+lm_ir

l <- data.frame(Model = "LM",MSE = lm_MSE, Bias_square= lm_bias2,var = lm_var, Irreducible = lm_ir, sum = l_sum )
```

```{r}
sp_MSE <- MSE(ymeans-results2)
sp_bias2 <- bias2S
sp_var  <-  var(ymeans-results2)
sp_ir <- var(ymeans)
s_sum <-sp_bias2 + sp_var+ sp_ir

s <- data.frame(Model = "Spline",MSE = sp_MSE, Bias_square= sp_bias2,var = sp_var, Irreducible = sp_ir, sum = s_sum)
output <- full_join(l,s)
output %>% kable(digits=)
```




# Analysis

**Questions**:

1. Based on the topics covered in Lec 2.7, name one possible "sanity check" for your results. Name another if you can.
2. In **two** sentences or less, give a rough sketch of what the procedure would
be to get the breakdown of $$\mbox{MSE}\left[\widehat{f}(x)\right]$$ for *all*
$x$ in this example, and not just for $$\mbox{MSE}\left[\widehat{f}(x_0)\right]
= \mbox{MSE}\left[\widehat{f}(0.95)\right]$$.


3. Which of the two models would you choose for predicting the point of interest and why?

**Answers**:

1. Our main sanity check for these results would be verifying that the simplier model (LM) indeed has a lower variance than the more complex model (Spline).  Conversely, we could also observe that the simplier model has a higher bias than the more complex model.

2. We would need to create a test set from out simulation, eg. we would assign one of our 10,000 samples of $n=500$ to serve as the test data.  Then, we would build a model for each other 9,999 sets then make predictions for $y$ ( perhaps report the RMSE value since we will have to compute a large number of values and store them in a list ) on each using our test set.  

3. The LM model does not lose out significantly to the spline model in terms of MSE, thus we go with it, as it is the simplier model.